{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\":\"success\",\"result\":[{\"message\":\"success\",\"input\":\"20200114_0950_Lek_A5_Flight_01_00007.JPG\",\"prediction\":[]}]}\n",
      "{\"message\":\"success\",\"result\":[{\"message\":\"success\",\"input\":\"20200114_0950_Lek_A5_Flight_01_00014.JPG\",\"prediction\":[{\"label\":\"Oil_Spill\",\"xmin\":935,\"ymin\":3748,\"xmax\":1935,\"ymax\":5287,\"score\":0.8830768},{\"label\":\"Oil_Spill\",\"xmin\":959,\"ymin\":3531,\"xmax\":3110,\"ymax\":5247,\"score\":0.81634825}]}]}\n",
      "{\"message\":\"success\",\"result\":[{\"message\":\"success\",\"input\":\"20200114_0950_Lek_A5_Flight_01_00042.JPG\",\"prediction\":[{\"label\":\"Oil_Spill\",\"xmin\":291,\"ymin\":56,\"xmax\":1990,\"ymax\":2044,\"score\":0.87230736}]}]}\n",
      "{\"message\":\"success\",\"result\":[{\"message\":\"success\",\"input\":\"Lekhwair_A_14012020_OilLeak_01,305350.JPG\",\"prediction\":[{\"label\":\"Oil_Spill\",\"xmin\":1436,\"ymin\":3631,\"xmax\":3249,\"ymax\":5304,\"score\":0.9719354},{\"label\":\"Oil_Spill\",\"xmin\":4250,\"ymin\":643,\"xmax\":5657,\"ymax\":2971,\"score\":0.7751789}]}]}\n",
      "{\"message\":\"success\",\"result\":[{\"message\":\"success\",\"input\":\"Lekhwair_A_14012020_OilLeak_02,1266670.JPG\",\"prediction\":[{\"label\":\"Oil_Spill\",\"xmin\":96,\"ymin\":2636,\"xmax\":2638,\"ymax\":5267,\"score\":0.7571811},{\"label\":\"Oil_Spill\",\"xmin\":5246,\"ymin\":1931,\"xmax\":6608,\"ymax\":3116,\"score\":0.711566}]}]}\n",
      "{\"message\":\"success\",\"result\":[{\"message\":\"success\",\"input\":\"Lekhwair_A_14012020_OilLeak_03,720000.JPG\",\"prediction\":[]}]}\n",
      "{\"message\":\"success\",\"result\":[{\"message\":\"success\",\"input\":\"Lekhwair_A_14012020_OilLeak_04,846330.JPG\",\"prediction\":[{\"label\":\"Oil_Spill\",\"xmin\":5784,\"ymin\":110,\"xmax\":7952,\"ymax\":2269,\"score\":0.92829436}]}]}\n",
      "{\"message\":\"success\",\"result\":[{\"message\":\"success\",\"input\":\"Lekhwair_A_14012020_OilLeak_05,898430.JPG\",\"prediction\":[]}]}\n",
      "{\"message\":\"success\",\"result\":[{\"message\":\"success\",\"input\":\"Lekhwair_A_14012020_OilLeak_06,850930.JPG\",\"prediction\":[{\"label\":\"Oil_Spill\",\"xmin\":1772,\"ymin\":4402,\"xmax\":3651,\"ymax\":5246,\"score\":0.7587571},{\"label\":\"Oil_Spill\",\"xmin\":1798,\"ymin\":4153,\"xmax\":4676,\"ymax\":5258,\"score\":0.67965716}]}]}\n",
      "['C:\\\\Users\\\\sami\\\\Desktop\\\\test images\\\\leak\\\\20200114_0950_Lek_A5_Flight_01_00014.JPG leak1.jpg', 'C:\\\\Users\\\\sami\\\\Desktop\\\\test images\\\\leak\\\\20200114_0950_Lek_A5_Flight_01_00042.JPG leak2.jpg', 'C:\\\\Users\\\\sami\\\\Desktop\\\\test images\\\\leak\\\\Lekhwair_A_14012020_OilLeak_01,305350.JPG leak3.jpg', 'C:\\\\Users\\\\sami\\\\Desktop\\\\test images\\\\leak\\\\Lekhwair_A_14012020_OilLeak_02,1266670.JPG leak4.jpg', 'C:\\\\Users\\\\sami\\\\Desktop\\\\test images\\\\leak\\\\Lekhwair_A_14012020_OilLeak_04,846330.JPG leak6.jpg', 'C:\\\\Users\\\\sami\\\\Desktop\\\\test images\\\\leak\\\\Lekhwair_A_14012020_OilLeak_06,850930.JPG leak8.jpg']\n",
      "Enter the area values 'make sure its the same numer of the images': 12 2 5 6 9 4 7 5 8\n",
      "Enter the leak/noleak 'make sure its the same numer of the images': no no no no no no yes ye eys\n",
      "Type the number of flights: 2\n",
      "Type the Report ID: LEK009\n",
      "Duration: 0:02:44.735479\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import requests\n",
    "import json\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import time\n",
    "from PIL.ExifTags import TAGS, GPSTAGS\n",
    "import exifread\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "\n",
    "\n",
    "#Oil Spill Model\n",
    "url = 'http://localhost:8081/'\n",
    "#url = 'https://app.nanonets.com/api/v2/ObjectDetection/Model/cdae82fe-76e4-4bcd-ab81-aefd9686a711/LabelFile/'\n",
    "\n",
    "filepath = ('C:\\\\Users\\\\sami\\\\Desktop\\\\test images\\\\*.*') # change this path\n",
    "save_anomaly_path = 'C:\\\\Users\\\\sami\\\\Desktop\\\\test images\\\\leak\\\\'# change this path\n",
    "\n",
    "filepath_leak = 'C:\\\\Users\\\\sami\\\\Desktop\\\\test images\\\\leak\\\\*.*'# change this path\n",
    "save_none_path = 'C:\\\\Users\\\\sami\\\\Desktop\\\\test images\\\\noLeak\\\\'# change this path\n",
    "\n",
    "\n",
    "name_images = []\n",
    "name_leak =[]\n",
    "#images_location =[]\n",
    "leak_images_location=[]\n",
    "geotagging = {}\n",
    "leak =[]\n",
    "leak_images =[]\n",
    "\n",
    "# Extract Images Location\n",
    "def get_geotagging(exif):\n",
    "    if not exif:\n",
    "        raise ValueError(\"No EXIF metadata found\")\n",
    "    \n",
    "    for (idx, tag) in TAGS.items():\n",
    "        if tag == 'GPSInfo':\n",
    "            if idx not in exif:\n",
    "                raise ValueError(\"No EXIF geotagging found\")\n",
    "\n",
    "            for (key, val) in GPSTAGS.items():\n",
    "                if key in exif[idx]:\n",
    "                    geotagging[val] = exif[idx][key]                 \n",
    "\n",
    "    return geotagging\n",
    "\n",
    "def get_dms(dms):    \n",
    "    degrees = dms[0][0] / dms[0][1]\n",
    "    minutes = dms[1][0] / dms[1][1] \n",
    "    seconds = dms[2][0] / dms[2][1] \n",
    "    \n",
    "    return round (degrees,2) , round (minutes,2) , round (seconds,2)\n",
    "\n",
    "def get_coordinates_dms(geatags):\n",
    "    lat = get_dms(geotags['GPSLatitude'])\n",
    "    lon = get_dms(geotags['GPSLongitude'])\n",
    "\n",
    "    return lat, geotags['GPSLatitudeRef'], lon, geotags['GPSLongitudeRef']\n",
    "\n",
    "\n",
    "for bb,f1 in enumerate (glob.glob(filepath)):       \n",
    "    #Extract images names\n",
    "    img_name = os.path.basename(f1)   \n",
    "    name_images.append(img_name)\n",
    "      \n",
    "    #Extract image date (Only ONE image)\n",
    "    if (bb < 1):\n",
    "        im = Image.open(f1)\n",
    "        exif = im.getexif()\n",
    "        creation_time = exif.get(36867)\n",
    "        onlyDate = ('%.11s' % creation_time)\n",
    "        #print(onlyDate)\n",
    "        \n",
    "        \n",
    "    data = {'file': open(f1, 'rb')}\n",
    "    \n",
    "    response = requests.post(url, auth=requests.auth.HTTPBasicAuth('API_KEY', ''), files=data)\n",
    "    print(response.text)\n",
    "    \n",
    "    img = cv2.imread(f1) # read image\n",
    "    \n",
    "    response_json = json.loads(response.text)\n",
    "    \n",
    "    prediction = response_json[\"result\"][0][\"prediction\"]\n",
    "    \n",
    "    LEAK_MIN_THRESHOLD = 0.50 # experiment with different threshold level between 0.0-1.0\n",
    "        \n",
    "    for i in prediction:\n",
    "        if (i['label']) == ('Oil_Spill'):\n",
    "            leak.append(i['score'])\n",
    "            \n",
    "            if max(leak) >= LEAK_MIN_THRESHOLD:\n",
    "                    \n",
    "                if (i['score']) >= LEAK_MIN_THRESHOLD:    \n",
    "                    img = cv2.rectangle(img,(i['xmin'],i['ymin']),(i['xmax'],i['ymax']),(0,0,255),10)\n",
    "                    cv2.imwrite(save_anomaly_path + str(os.path.basename(f1)) +' leak{}.jpg'.format(bb), img)\n",
    "                    \n",
    "                    #Make Dictionary for images with leaks only\n",
    "                    if len(leak)<2:    \n",
    "                        leak_images.append(f1)\n",
    "                \n",
    "                    #Extract images names of leaks\n",
    "                        img_name_leak = os.path.basename(f1)   \n",
    "                        name_leak.append(img_name_leak)\n",
    "                \n",
    "                    #image loctaion\n",
    "                        exif = Image.open(f1)._getexif()\n",
    "                        geotags = get_geotagging(exif)\n",
    "                        leak_images_location.append(get_coordinates_dms(geotags))\n",
    "                   \n",
    "        \n",
    "            if max(leak) < LEAK_MIN_THRESHOLD:\n",
    "                cv2.imwrite(save_none_path + str(os.path.basename(f1)) +' no{}.jpg'.format(bb), img)\n",
    "                                     \n",
    "            \n",
    "    if len(leak) ==0:\n",
    "        cv2.imwrite(save_none_path + str(os.path.basename(f1)) +' no{}.jpg'.format(bb), img)\n",
    "                        \n",
    "    leak=[]  \n",
    "\n",
    "#predict leak images\n",
    "predict_leak =[]\n",
    "\n",
    "for cc,p1 in enumerate (glob.glob(filepath_leak)):\n",
    "    predict_leak.append(p1)\n",
    "print(predict_leak)\n",
    "\n",
    "\n",
    "# calculate number of images\n",
    "No_images = len(name_images)\n",
    "    \n",
    "# Generate Sequence Numbers of leak \n",
    "NO_leak =[]\n",
    "for i in range(2000):\n",
    "    if i < len(leak_images):\n",
    "        \n",
    "        NO_leak.append(i+1)\n",
    "\n",
    "\n",
    "\n",
    "#create Dictionary for leak images\n",
    "#Take Info from User\n",
    "area = list(map(int, input(\"Enter the area values 'make sure its the same numer of the images': \").split()))\n",
    "#area = [\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"]  #write here the areas (must be the same number of images)\n",
    "oldNew = list(map(str, input(\"is the leak old/new leak 'make sure its the same numer of the images': \").split()))\n",
    "\n",
    "#Dictionary of leak Images\n",
    "keys1 = \"NO\", \"Name\", \"Location\", \"Image\", \"Area\", \"OldNew\"\n",
    "subject2 = NO_leak,name_leak,leak_images_location, predict_leak, area , oldNew\n",
    "leak_dic = {z[0]:list(z[1:]) for z in zip(keys1* len(subject2),subject2)}\n",
    "#print (leak_dic)\n",
    "\n",
    "\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------------------------------#    \n",
    "#---------------------------------------------------------------------------------------------------------------------#   \n",
    "# Creating the PDF using ReportLab\n",
    "\n",
    "\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.pagesizes import letter, inch\n",
    "from reportlab.platypus import Image, Paragraph, SimpleDocTemplate, Table\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "\n",
    "doc = SimpleDocTemplate(\"C:\\\\Users\\\\sami\\\\Desktop\\\\test images\\\\report\\\\Anomalies Detected.pdf\", pagesize=letter) #change this path\n",
    "#container for the 'Flowable' objects\n",
    "elements = []\n",
    " \n",
    "\n",
    "#Table 1\n",
    "Ip = Image('pdo.jpg')\n",
    "Ip.drawHeight = 1.25*inch*Ip.drawHeight / Ip.drawWidth\n",
    "Ip.drawWidth = 1.25*inch\n",
    "\n",
    "Ih = Image('haitch.png')\n",
    "Ih.drawHeight = 1.25*inch*Ih.drawHeight / Ih.drawWidth\n",
    "Ih.drawWidth = 1.25*inch\n",
    "\n",
    "\n",
    "data1= [[Ip,'\"Flowiness Anomalies Report\"', Ih],[  ]]\n",
    "\n",
    " \n",
    "t1=Table(data1,style=[('ALIGN',(0,0),(-1,-1),'CENTER'),\n",
    "                    ('VALIGN',(0,0),(-1,-1),'MIDDLE'),\n",
    "                    ('FONTSIZE', (0, 0), (-1, -1), 15),\n",
    "                    ('BOX',(0,0),(-1,0),0.5,colors.black),\n",
    "                    ('GRID',(0,0), (-1,0), 0.5,colors.black),\n",
    "                    ])\n",
    "t1._argW[2]=1.7*inch\n",
    "t1._argW[1]=3.5*inch\n",
    "t1._argW[0]=1.7*inch\n",
    " \n",
    "elements.append(t1)\n",
    "\n",
    "\n",
    "\n",
    "#Extract Info from User:\n",
    "numFlights = input(\"Type the number of flights: \")\n",
    "#print(\"Your Number of Flights is: \", numFlights)\n",
    "\n",
    "reportID = input(\"Type the Report ID: \")\n",
    "\n",
    "#Table 2\n",
    "data2= [[\"Date\", onlyDate],\n",
    "       [\"Location\", \" ???\"],\n",
    "       [\"Method of Inspection\", \"UAS\"],\n",
    "       [\"Methos of Analysis\", \"AI\"],\n",
    "       [\"Number of flights\", numFlights+\" Flights\"], #change Number of Flights\n",
    "       [\"Number of collected Images\", (str(No_images)+\" Images\")],\n",
    "       [\"Flight Altitude Range\", \"50 - 100 m\"],\n",
    "       [\"Report ID\", reportID]] # Change\n",
    " \n",
    "t2=Table(data2,style=[('ALIGN',(0,0),(-1,-1),'LEFT'),\n",
    "                    ('VALIGN',(0,0),(-1,-1),'MIDDLE'),\n",
    "                    ('BOX',(0,0),(-1,-1),0.5,colors.black),\n",
    "                    ('GRID',(0,0), (-1,-1), 0.5,colors.black),\n",
    "                    \n",
    "])\n",
    "t2._argW[1]=3.5*inch\n",
    "t2._argW[0]=3.5*inch\n",
    "\n",
    "elements.append(t2)\n",
    "\n",
    "styleP = getSampleStyleSheet()['Normal']\n",
    "#style.leading = 24\n",
    "#style.fontName = 'Helvetica'\n",
    "#style.alignment = TA_JUSTIFY\n",
    "styleP.spaceAfter = 24\n",
    "\n",
    "space1 = Paragraph('''''',styleP)\n",
    "elements.append(space1)\n",
    "\n",
    "\n",
    "#Table 3\n",
    "\n",
    "def table3(no, location, area, oldNew, img):\n",
    "    \n",
    "    \n",
    "    #area = \"???\" # Change area here\n",
    "    #oldNew = \"???\" # change this\n",
    "    \n",
    "    data3= [[\"No\",\"Anomaly\", \"Location Coordinates\", \"Estimated Area\", \"Old/New leak\"],\n",
    "           [str(no), \" Oil Spill\",str(location), area, oldNew],\n",
    "           [ \"\",\"\" ,img,\"\",\"\"]]\n",
    "\n",
    " \n",
    "    t3=Table(data3,style=[('ALIGN',(0,0),(-1,-1),'CENTER'),\n",
    "                    ('VALIGN',(0,0),(-1,-1),'MIDDLE'),\n",
    "                    ('BOX',(0,0),(-1,-2),0.5,colors.black),\n",
    "                    ('GRID',(0,0), (-1,-2), 0.5,colors.black),\n",
    "                    ])\n",
    "    t3._argW[4]=1.5*inch\n",
    "    t3._argW[3]=1.0*inch\n",
    "    t3._argW[2]=3.0*inch\n",
    "    t3._argW[1]=1.0*inch\n",
    "    t3._argW[0]=0.5*inch\n",
    "    \n",
    "    return t3\n",
    "\n",
    "#Repeat Table 3 from Leak Dictionary\n",
    "\n",
    "for i in range(len(NO_leak)):\n",
    "    Img = Image(leak_dic[\"Image\"][0][i])\n",
    "    Img.drawHeight = 3.25*inch*Ip.drawHeight / Ip.drawWidth\n",
    "    Img.drawWidth = 3.25*inch\n",
    "    \n",
    "    elements.append(table3(leak_dic[\"NO\"][0][i],\n",
    "                           leak_dic[\"Location\"][0][i],\n",
    "                           leak_dic[\"Area\"][0][i],\n",
    "                           leak_dic[\"OldNew\"][0][i],\n",
    "                           Img))\n",
    "    space2 = Paragraph('''''', styleP)\n",
    "    elements.append(space2)\n",
    "\n",
    "\n",
    "# write the document to disk\n",
    "doc.build(elements)\n",
    "\n",
    "\n",
    "#Print Duration Time of Model\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
